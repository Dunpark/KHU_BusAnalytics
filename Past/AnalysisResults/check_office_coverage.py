"""
ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ + ìƒê¶Œ_ì½”ë“œ ì¡°í•©ì´
ì§ì¥ì¸êµ¬ ë°ì´í„°ì— ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
"""

import pandas as pd
import sys

MERGED_PATH = "../Merged_datasets/4ê°œë…„_í†µí•©ë°ì´í„°_ì¶”ì •ë§¤ì¶œ_ìƒì£¼ì¸êµ¬_ì†Œë“ì†Œë¹„_ê¸¸ë‹¨ìœ„ì¸êµ¬_ì í¬_ì˜ì—­.csv"
OFFICE_PATH = "../Data_Raw_new/ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤(ì§ì¥ì¸êµ¬-ìƒê¶Œ).csv"


def read_with_encodings(path, encodings=("utf-8", "utf-8-sig", "cp949", "euc-kr")):
    for enc in encodings:
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    raise RuntimeError(f"Cannot read file with tried encodings: {encodings}")


def main():
    print("=" * 80)
    print("ğŸ“Š ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ Ã— ìƒê¶Œ_ì½”ë“œ ì¡°í•© ë§¤í•‘ ê²€ì‚¬")
    print("=" * 80)

    merged = pd.read_csv(
        MERGED_PATH,
        encoding="utf-8",
        usecols=["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ", "ìƒê¶Œ_ì½”ë“œ"],
    )
    merged["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] = merged["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].astype(int)
    merged["ìƒê¶Œ_ì½”ë“œ"] = merged["ìƒê¶Œ_ì½”ë“œ"].astype(int)

    office = read_with_encodings(OFFICE_PATH)
    # ì§ì¥ì¸êµ¬ íŒŒì¼ì€ ë³´í†µ ì—´ ì´ë¦„ì´ ê°™ê±°ë‚˜ ëŒ€ì†Œë¬¸ì/ì–¸ë”ìŠ¤ì½”ì–´ ì°¨ì´ ì—†ìŒ
    if "ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ" not in office.columns or "ìƒê¶Œ_ì½”ë“œ" not in office.columns:
        print(f"âŒ ì§ì¥ì¸êµ¬ íŒŒì¼ì— í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ì—´ ëª©ë¡: {office.columns.tolist()}")
        sys.exit(1)

    office = office[["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ", "ìƒê¶Œ_ì½”ë“œ"]].copy()
    office["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] = office["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].astype(int)
    office["ìƒê¶Œ_ì½”ë“œ"] = office["ìƒê¶Œ_ì½”ë“œ"].astype(int)

    merged_combos = (
        merged.drop_duplicates(subset=["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ", "ìƒê¶Œ_ì½”ë“œ"])
        .assign(key=lambda x: list(zip(x["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"], x["ìƒê¶Œ_ì½”ë“œ"])))
        ["key"]
    )
    office_combos = (
        office.drop_duplicates(subset=["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ", "ìƒê¶Œ_ì½”ë“œ"])
        .assign(key=lambda x: list(zip(x["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"], x["ìƒê¶Œ_ì½”ë“œ"])))
        ["key"]
    )

    merged_set = set(merged_combos)
    office_set = set(office_combos)

    missing = merged_set - office_set

    total = len(merged_set)
    missing_cnt = len(missing)
    covered = total - missing_cnt
    missing_ratio = missing_cnt / total * 100 if total else 0

    print(f"\n[ì¡°í•© ê°œìˆ˜]")
    print(f"  â€¢ Merged ë°ì´í„° ì¡°í•© ìˆ˜: {total:,}")
    print(f"  â€¢ ì§ì¥ì¸êµ¬ ë°ì´í„° ì¡°í•© ìˆ˜: {len(office_set):,}")

    print(f"\n[ë§¤í•‘ ê²°ê³¼]")
    print(f"  â€¢ ë§¤í•‘ë¨: {covered:,}ê°œ ({100 - missing_ratio:.2f}%)")
    print(f"  â€¢ ë§¤í•‘ ì•ˆ ë¨: {missing_cnt:,}ê°œ ({missing_ratio:.2f}%)")

    # ëˆ„ë½ëœ ì¡°í•© ìƒ˜í”Œ 20ê°œ ì¶œë ¥
    if missing_cnt > 0:
        print("\n[ë§¤í•‘ ì•ˆ ëœ ì¡°í•© ìƒ˜í”Œ 20ê°œ] (ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ, ìƒê¶Œ_ì½”ë“œ)")
        for tup in list(missing)[:20]:
            print(f"  {tup[0]}, {tup[1]}")

    print("\nâœ… ì™„ë£Œ")


if __name__ == "__main__":
    main()


